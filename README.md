# Aditya Bhavar | Senior Data Engineer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/adityabhavar/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/adityabhavar)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:adityabhavar1006@gmail.com)
[![Phone](https://img.shields.io/badge/Phone-25D366?style=for-the-badge&logo=phone&logoColor=white)](tel:+919011777105)

## ğŸ’« About Me

Results-driven **Senior Data Engineer** with 3+ years of experience building high-performance data solutions. I specialize in:

- ğŸš€ Designing scalable data pipelines that reduce processing time by up to 98%
- ğŸ’° Optimizing cloud infrastructure to cut costs by 30-60%
- ğŸ¤– Implementing end-to-end AI/ML solutions from development to production
- ğŸ”„ Building real-time data processing systems with Kafka and stream processing

I'm passionate about transforming complex data challenges into elegant, efficient solutions that deliver real business value.

## ğŸ› ï¸ Technical Skills

### Languages & Core Technologies
![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=flat-square&logo=react&logoColor=61DAFB)
![Bash](https://img.shields.io/badge/Bash-4EAA25?style=flat-square&logo=gnu-bash&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=flat-square&logo=postgresql&logoColor=white)

### Frameworks & Libraries
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat-square&logo=fastapi&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=flat-square&logo=flask&logoColor=white)
![Django](https://img.shields.io/badge/Django-092E20?style=flat-square&logo=django&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-3670A0?style=flat-square&logo=chainlink&logoColor=white)

### Cloud & DevOps
![AWS](https://img.shields.io/badge/AWS-232F3E?style=flat-square&logo=amazon-aws&logoColor=white)
![Azure](https://img.shields.io/badge/Azure-0078D4?style=flat-square&logo=microsoft-azure&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=flat-square&logo=kubernetes&logoColor=white)
![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=flat-square&logo=github-actions&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache_Kafka-231F20?style=flat-square&logo=apache-kafka&logoColor=white)

### Databases
![MySQL](https://img.shields.io/badge/MySQL-4479A1?style=flat-square&logo=mysql&logoColor=white)
![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=flat-square&logo=mongodb&logoColor=white)
![DynamoDB](https://img.shields.io/badge/DynamoDB-4053D6?style=flat-square&logo=amazon-dynamodb&logoColor=white)
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=flat-square&logo=snowflake&logoColor=white)
![Redshift](https://img.shields.io/badge/Redshift-8C4FFF?style=flat-square&logo=amazon-aws&logoColor=white)

### AI/ML
![NLP](https://img.shields.io/badge/NLP-3670A0?style=flat-square&logo=natural-language-processing&logoColor=white)
![LLMs](https://img.shields.io/badge/LLMs-DD0031?style=flat-square&logo=openai&logoColor=white)
![MLOps](https://img.shields.io/badge/MLOps-FF6F00?style=flat-square&logo=mlflow&logoColor=white)
![Time Series](https://img.shields.io/badge/Time_Series-026E00?style=flat-square&logo=influxdb&logoColor=white)

## ğŸ† Professional Experience

### Senior Data Engineer @ Namasys Private Limited (May 2022 - Present)

- âš¡ **Pipeline Optimization:** Architected 50+ data pipelines using AWS, Azure, and PySpark, reducing code volume by 95% and boosting efficiency by 60%
- ğŸ“Š **Big Data Processing:** Automated ETL workflows for 100+ TB of data, cutting compute costs by 33% and storage costs by 60%
- â±ï¸ **Performance Tuning:** Transformed multi-day batch processes into 20-30 minute PySpark jobs through advanced optimization techniques
- ğŸ”„ **Real-time Systems:** Developed low-latency data update pipelines using Kafka for real-time analytics and decision support
- ğŸ¤– **AI/ML Enablement:** Led end-to-end AI initiatives including GenAI chatbot development and ML observability, improving model performance by 20-40%
- ğŸ” **DevOps Integration:** Implemented GitHub Actions CI/CD pipelines for automated quality checks, deployment, and alerting

## ğŸš€ Key Projects

### AION - AI Lifecycle Management Platform
A comprehensive platform for managing the complete AI/ML lifecycle from development to production.

- ğŸ§  **Platform Agnostic:** Built with Docker, REST APIs, and custom Python packages to work across computing environments
- ğŸ“ˆ **Model Reliability:** Enhanced model performance with drift detection and monitoring, achieving 95% accuracy
- âš™ï¸ **Data Integration:** Automated data preparation and ingestion, boosting data scientist productivity by 20%
- ğŸ”Œ **Cross-platform:** Improved compatibility by 40% using Python-based solutions for seamless deployment

### Generative AI Chatbot for Authors
An AI-powered assistant to help authors with content creation and research.

- ğŸ¤– **Multi-agent Architecture:** Implemented using LangGraph and Crew AI for sophisticated reasoning and collaboration
- ğŸ“ **Content Generation:** Developed AI-powered utilities for drafting, editing, and researching content
- ğŸš€ **Scalable Deployment:** Built containerized solutions on AWS using Docker for elastic scaling based on demand

### Enterprise Data Pipelines
End-to-end data infrastructure for integrating, processing, and analyzing enterprise data.

- ğŸ”„ **Data Integration:** Connected multiple APIs and data sources into centralized data warehouses on Azure SQL and AWS Redshift
- âš¡ **Real-time Processing:** Implemented Kafka-based streaming for near real-time data availability
- ğŸ” **Quality Automation:** Created automated data quality checks and alerts using GitHub Actions

## ğŸ“š Education

**Bachelor of Engineering in Electronics**  
State University | GPA: 8.7 | Honors: AI & Machine Learning

## ğŸ“« Let's Connect!

I'm always interested in challenging data engineering problems and collaborating on innovative projects. Feel free to reach out!

- ğŸ“§ **Email:** adityabhavar1006@gmail.com
- ğŸ“± **Phone:** +91 9011777105
- ğŸ’¼ **LinkedIn:** [adityabhavar](https://www.linkedin.com/in/adityabhavar/)
- ğŸ™ **GitHub:** [adityabhavar](https://github.com/adityabhavar)

---

âš¡ **Fun Fact:** I once optimized a data pipeline that reduced processing time from 2 days to just 20 minutes, saving the company over $10,000 per month in compute costs!
